Bem-vindo ao fascinante mundo dos Modelos de Linguagem de Grande Escala (LLMs) e das técnicas básicas de criação de prompts! Nesta primeira aula, vamos explorar o que realmente são os LLMs. Spoiler! Eles são essencialmente máquinas de previsão de próxima palavra. Pode parecer simples, mas há muito mais do que aparenta. Se você é totalmente novo em programação ou está apenas curioso sobre como essas maravilhas tecnológicas funcionam, você está no lugar certo. Vamos embarcar juntos nesta empolgante jornada e desvendar os mistérios dos LLMs, começando com sua funcionalidade central.

__Entendendo os LLMs como Máquinas de Previsão de Próxima Palavra__

Imagine que você está escrevendo uma mensagem de texto ou um e-mail, e seu telefone sugere a próxima palavra que você talvez queira digitar. Esse é um exemplo muito básico do que os Modelos de Linguagem de Grande Escala (LLMs) fazem. No entanto, LLMs como GPT-3.5, GPT-4 (mais conhecido como chatGPT), Claude 2 e LLaMA são como super-heróis da previsão de palavras. Eles não sugerem apenas a próxima palavra em uma frase; eles podem gerar parágrafos inteiros de texto que fazem sentido com base na entrada recebida. Eles fazem isso prevendo, de forma sequencial, a próxima palavra que continua o texto que já têm.

No fundo, os LLMs analisam uma quantidade imensa de dados textuais. Através dessa análise, eles aprendem padrões, nuances e a estrutura da linguagem. Isso os habilita a prever qual palavra vem naturalmente em seguida em uma série de palavras. É como se eles estivessem constantemente jogando “complete a lacuna”, mas em uma escala e velocidade impressionantes.

__Como os LLMs Fazem Previsões?__

Você pode se perguntar como os LLMs conseguem fazer essas previsões. Bem, tudo se resume ao treinamento. Os LLMs são expostos a enormes conjuntos de dados que incluem desde livros e artigos até websites e mais. Durante essa fase de treinamento, eles aprendem a entender o contexto e o fluxo da linguagem. Eles absorvem elementos como gramática, estilo e até o tom do texto.

Quando você fornece um prompt a um LLM com uma frase ou uma pergunta, ele utiliza o que aprendeu para prever a próxima palavra ou as palavras mais prováveis que seguirão. Isso não é apenas um palpite aleatório; é uma previsão calculada baseada nos padrões e regras que ele observou durante o treinamento.

__Vamos Praticar um Pouco de Engenharia de Prompt__

Dada a natureza probabilística dos LLMs, o desafio para os Engenheiros de Prompt é guiar os LLMs para resultados altamente previsíveis e precisos, de forma consistente.

Como parte deste curso, você aprenderá muitas técnicas que permitirão dominar a arte e a ciência de obter respostas altamente previsíveis dos LLMs. Mas antes de irmos longe demais, vamos começar com alguns exercícios simples para aquecer as engrenagens.

__EXERCÍCIO__

Nesse exercício você simplesmente vai abrir um chat na sua IA de preferência e digitar:

*antes tarde do que*

E assista a mágica acontecer.

Acesse o assistente do treinamento Prompt Engineer no ChatGPT:
https://chatgpt.com/g/g-673111c11bf08190803da09a71ca211c-prompt-engineer

